---
title: Momentum Contrast for Unsupervised Visual Representation Learning
alias:
  - MoCoV1
  - he2020
tags:
  - SSL
rating: ⭐⭐⭐
shared: true
ptype: article
draft: false
date: 2023-01-09
---


# Momentum Contrast for Unsupervised Visual Representation Learning
<cite>* Authors: [[Kaiming He]], [[Haoqi Fan]], [[Yuxin Wu]], [[Saining Xie]], [[Ross Girshick]]</cite>

* DOI: [10.1109/CVPR42600.2020.00975](https://doi.org/10.1109/CVPR42600.2020.00975)

* [Local library](zotero://select/items/1_LIZ9BQQ9)

---

- MoCo v2: [[@chen2020]]
- MoCo v3: [[@chen2021a]]

***

### 初读印象

comment:: 用动量更新替代负类 Encoder $f_{Mk}$ 使用反向传播时 batch size 不能太大的问题， 同时设置动量使得 $f_{Mk}$ 遗忘很缓慢，间接使模型看到尽可能多的负样本 。每个 epoch 都会更新 momentum encoder ，解决 Encoder $f_q$ 和 Momentum Encoder $f_{Mk}$ 不一致的问题。



### InfoNCE loss


$$L_q=-log\dfrac{exp(q\cdot k_+/\tau)}{\sum_{i=0}^k exp(q\cdot k_i/\tau))}$$

抛开温度系数， InfoNCE loss 和 cross entropy loss 是一样， 只是 cross entropy  loss 里 k 指的是类别数目, 而 infoNCE 里指的是 负类数量， 由于累加是从 0 开始的， 所以总样本数是包含一个正类的 k + 1 个。

温度系数的作用：$\tau$ 越大，会使 logits 数值变小，变得更平滑，$\tau$ 越小 logits  数值变大， 使得分布更加集中，更加 peak。


